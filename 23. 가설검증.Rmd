# 가설 검정

### 카이제곱 검정

: 두 범주형 변수가 서로 상관이 있는지 판단하는 통계적 검정 방법.

예) 학력, 성별, 직업의 만족도

범주형 변수란 **고유한 값이나 범주 수가 제한된 변수**(예: 성별 또는 종교)입니다. 범주형 변수는 명목이거나 순서일 수 있습니다. 명목 . 변수의 값이 고유한 순위가 없는 범주를 나타내는 경우 해당 변수는 명목으로 취급될 수 있습니다.

이럴땐 카이제곱 검정을 쓰는구나\~ 를 할아야 댐

## Child 별 장난감 보유현황

아이들의 장난감 갯수로 행복도를 측정할 수 있다/없다

-   귀무가설 : child_1 과 child_2의 장난감 보유수에 대한 만족도는 차이가 없다.

    귀무가설(null hypothesis)은 **우리가 증명하고자 하는 가설의 반대되는 가설, 효과와 차이가 없는 가설**

-   대립가설 : child_1 과 child_2의 장난감 보유수에 대한 만족도는 차이가 있다.

    우리가 증명 또는 입증하고자 하는 가설, 효과와 차이가 있는 가설

```{r}
#예제 데이터 
ch1 <- c(5,11,1)
ch2 <- c(4,7,3)

```

```{r}
#분석하기 위해 데이터를 합치자
Toy <- cbind(ch1, ch2)
Toy
```

```{r}
# names
rownames(Toy) <- c("car","truck",'doll')
Toy
```

### 카이제곱 검정을 실시

```{r}
chisq.test(Toy)
```

### 결론

    1. p-value = 0.4219 

    p-value > 0.05 : 95% 신뢰구간, 귀무가설 채택 
      --> child_1 과 child_2 의 데이터는 통계적으로 큰 차이가 없다
    p-value < 0.05 : 여기로 오면 대립가설 채택


    p-value 는 0에 가까울수록 좋다. 
      미리 정해준 유의수준( 일반적으로 0.05 ) 보다 작으면 대립가설을 채택하고
      유의수준보다 크면 귀무가설을 채택한다
      

    2. Message(Warning) : 카이제곱의 근사값이 정확하지 않을 수도 있다. 
      --> 데이터량이 적은경우 발생.
      
      피셔검정 : 표본수가 적거나 데이터의 분포가 치우진 경우 사용
      (fisher)

### fisher.test

```{r}
fisher.test(Toy)
```

    two.sided 는 그래프에서 왼/오 2.5% 씩 뺀 뒤 나머지 95% 에서 통게한거 (?)

```{r}
# 상관관계 
cor(ch1,ch2)  # = 0.9862414
```

# T- 검정

귀무가설 : 건전지의 수명은 1000시간 이다.

대립가설 : 건전지의 수명은 1000시간이 아니다!

1)  데이터의 분포가 정규분포 -\> Shapiro-Wilk 검정

-   귀무가설 : 자료가 정규분포를 따른다.

-   대립가설 : 자료가 정규분포를 따르지 않는다

### shapiro test

```{r}
bat <- c(980,1008, 968, 1032, 1012, 1002, 996, 1017) # 배터리 시간

shapiro.test(bat)

```

    p-value = 0.9469 > 0.05 -> 귀무가설 이다 
     --> 정규분포 이다 

```{r}
# shapiro 검정에서 정규분포가 확인되었으니 t 검정 시작 
t.test(bat, mu=1000, alternative = "two.sided")
# mu = 1000 는 평균 1000이 기준 
```

    mu           : 비교하넌 대상의 평균
    alternative  : 
          two.sided : 데이터와 평균과 다르다.
          greater   : 데이터가 평균보다 크다.
          less      : 데이터가 평균보다 적다.

    p-value = 0.8032 > 0.05 --> 귀무가설 ( 건전지의 수명은 1000시간 이다. )


    주로 광고 같은곳에서 검정을 사용할때 사용하는게 T-검정.
    평균값 하나와 비교해서 사용 

### 어떤 학교의 수학 점수 평균 : 55점

0교시 수업을 한 후 에 학생들의 성적이 올랐을까 ?

귀무가설 : 성적은 오르지 않았다.

대립가설 : 성적이 올랐다.

```{r}
exam <- read.csv("./Data/hanexam.csv", header = T)
```

```{r}
a <- exam$score
shapiro.test(a)
```

0.1058 \> 0.05 -\> 귀무가설 : 정규분포

```{r}
summary(a)

# mean 56.18
# 일반인의 기준으로는 기존 평균 55보다 평균이 56.18로 평균이 올랐으니
# 0교시 수업을 계속 하면 수학 점수가 오른다! 
# 정말 ?
```

```{r}
boxplot(a)
# 이상치 발견 
```

```{r}
t.test(a, mu=55, alternative = "greater")
# data는 a, 기준평균값은 55, 그것보다 올랐냐?
```

    p-value = 0.4046 > 0.05 -> 귀무가설 : 성적은 오르지 않았다 

# 상관관계

```{r}
# data의 순서는 중요하다
# 특히 상관관계 순서 바꾸면 아주 큰돈 받고 해야된다 
y <- c(2,1,4,3)
z <- c(0,5,7,9)
cor(y,z)
```

```{r}
cor(y,z,method="pearson") # 이건 디폴트값
cor(y,z,method="spearman") # 데이터가 적을땐  창술사 5개 이하정도 ..?

```

# 콜모고로프 - 스미노프 검정(KS Test)

: 주어진 2개의 데이터가 같은 분포인지를 검정하는 방법

귀무가설 : 두개의 데이터 분포가 다르다.

대립가설 : 두개의 데이터 분포가 같다 .

```{r}
# 예제 데이터
x <- rnorm(50)
y <- runif(50)
ks.test(x,y)


# 난수함수는 정규분포를 따라서 생성이 된다고 함 
```

    p-value = 0.00009909 < 0.05 : 0.05보다 적으므로 대립가설 : 데이터 분포가 같다 

# 부호검정

: 2개의 데이터 사이에 차이가 있는지 검정하는 것

식사전과 식사후의 음료수 맛에 대한 평가

```{r}
#예제 데이터  5점 만점
x <- c(4, 1, 1, 4, 3, 3, 2, 5, 4, 4) 
y <- c(1, 1, 3, 2, 5, 1, 4, 4, 3, 1)
```

귀무가설 : 유의한 차이가 없다

대립가설 : 유의한 차이가 있다

```{r}
binom.test(
            c(
              length(x[x>y]), length(x[x<y])  
              )
            )
```

언제 먹어도 맛이 변하지 않고 같아야 된다면 이 데이터는 좋은 데이터

# 비율 검정

: 2개의 데이터 사이에 비율의 차이가 있는지에 대한것을 검정

맥주를 좋아하시나요 ?? 라는 질문에

-   서울에서는 400명중 360명이 좋다

-   부산에서는 200명중 136명이 좋다

둘의 비율 차이가 있다고 할 수 있는가 ?

귀무가설 : 유의한 차이가 없다

대립가설 : 유의한 차이가 있다.

```{r}
hite <- c(360,136)
sample <- c(400,200)
prop.test(hite, sample)
```

    p-value = 0.00000000004207 < 0.05  대립가설 : 유의미한 차이가 있다. 

# 회귀분석

과거를 돌아봐서 미래를 예측한다

-   단순 회귀 분석 : column 하나, y = ax + b

-   다중 회귀 분석

```{r}
# 예제 데이터, 연령과 키,몸무게 데이터 
regression <- read.csv('./Data/regression.csv')
head(regression)
```

데이터 확인

```{r}
str(regression)
```

```{r}
summary(regression$Height)
summary(regression$Weight)
```

산포도 확인해보자

```{r}
plot(regression$Height, regression$Weight)
```

상관게수 확인

```{r}
cor(regression$Height, regression$Weight) # = 0.9672103

```

```{r}

plot(regression$Weight ~ regression$Height)


#회귀식 : lm(종속변수(y) ~ 독립변수(x))  x에 의해서 y값이 변하는.
lm(regression$Weight ~ regression$Height)

# 회귀선(중심선, 평균선 )
r <- lm(regression$Weight ~ regression$Height)
abline(r, col="red")
```

분석결과

```{r}
summary(r)
```

    1. p-value: < 0.00000000000000022  < 0.05

    2. Adjusted R-squared:  0.9333  <- 예측력 

    3. Residual standard error: 6.355 <- 표준오차

```{r}
r
# 계산식 
```

y = ax + b

몸무게 = 0.6147 \* 키 + (-40.8659)

```{r}
#키가 170cm 인 사람의 몸무게를 예측
0.6147 * 170 +  (-40.8659) # = 63.6331
# 이건 점쟁이 


# 표준오차를 적용한 키가 170인 사람의 몸무게
paste(0.6147 * 170 +  (-40.8659) -6.355, "~", 0.6147 * 170 +  (-40.8659) + 6.355)
# 이렇게 표현해야 통계 
```

\
